{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If yfinance is not already installed, uncomment the code block below, and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yfinance as yf  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "now = datetime.now()\n",
    "now = str(now.year)+\"-\"+str(now.month)+\"-\"+str(now.day)\n",
    "import requests\n",
    "import pandas as pd\n",
    "import arrow\n",
    "import datetime\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACD\n",
    "https://school.stockcharts.com/doku.php?id=technical_indicators:moving_average_convergence_divergence_macd\n",
    "\n",
    "\n",
    "As its name implies, the MACD is all about the convergence and divergence of the two moving averages. Convergence occurs when the moving averages move towards each other. Divergence occurs when the moving averages move away from each other. The shorter moving average (12-day) is faster and responsible for most MACD movements. The longer moving average (26-day) is slower and less reactive to price changes in the underlying security.\n",
    "\n",
    "The MACD line oscillates above and below the zero line, which is also known as the centerline. These crossovers signal that the 12-day EMA has crossed the 26-day EMA. The direction, of course, depends on the direction of the moving average cross. Positive MACD indicates that the 12-day EMA is above the 26-day EMA. Positive values increase as the shorter EMA diverges further from the longer EMA. This means upside momentum is increasing. Negative MACD values indicate that the 12-day EMA is below the 26-day EMA. Negative values increase as the shorter EMA diverges further below the longer EMA. This means downside momentum is increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Line\n",
    "\n",
    "Signal Line Crossovers\n",
    "Signal line crossovers are the most common MACD signals. The signal line is a 9-day EMA of the MACD line. As a moving average of the indicator, it trails the MACD and makes it easier to spot MACD turns. A bullish crossover occurs when the MACD turns up and crosses above the signal line. A bearish crossover occurs when the MACD turns down and crosses below the signal line. Crossovers can last a few days or a few weeks, depending on the strength of the move.\n",
    "\n",
    "Due diligence is required before relying on these common signals. Signal line crossovers at positive or negative extremes should be viewed with caution. Even though the MACD does not have upper and lower limits, chartists can estimate historical extremes with a simple visual assessment. It takes a strong move in the underlying security to push momentum to an extreme. Even though the move may continue, momentum is likely to slow and this will usually produce a signal line crossover at the extremities. Volatility in the underlying security can also increase the number of crossovers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stock_data(start_date,end_date,ticker):\n",
    "    data = yf.download(ticker,start_date,end_date)\n",
    "    data=data.reset_index()\n",
    "    data=data.sort_values('Date')\n",
    "    \n",
    "    #extract day of the week\n",
    "    mapping = {0:'Mon',1:'Tues',2:'Wed',3:'Thurs',4:'Fri',5:'Sat',6:'Sun'}\n",
    "    data['DOW'] = data['Date'].dt.dayofweek\n",
    "    data['DOW_Mapped'] =data['DOW'].map(mapping)\n",
    "    \n",
    "    \n",
    "    #calculate 7 day moving average with open and close\n",
    "    data['5Day_Moving_Average_Close'] = data['Close'].rolling(window=5).mean()\n",
    "    data['5Day_Moving_Average_Open'] = data['Open'].rolling(window=5).mean()\n",
    "    \n",
    "    #long ma \n",
    "    data['26Day_Moving_Average_Close'] = data['Close'].ewm(span=26).mean()\n",
    "    \n",
    "    #mid ma \n",
    "    data['12Day_Moving_Average_Close'] = data['Close'].ewm(span=12).mean()\n",
    "    \n",
    "    \n",
    "    #short ma\n",
    "    data['9Day_Moving_Average_Close'] = data['Close'].ewm(span=9).mean()\n",
    "    \n",
    "    \n",
    "    #MACD\n",
    "    data['MACD']=data['12Day_Moving_Average_Close']-data['26Day_Moving_Average_Close']\n",
    "    \n",
    "    \n",
    "    \n",
    "    #average the MACD to derive the signal line\n",
    "    data['signal'] = data['MACD'].ewm(span=9).mean()\n",
    "    \n",
    "    \n",
    "    # difference the macd from the sinal line to find the acceleration histogram\n",
    "    data['hist'] = data['MACD'] - data['signal']\n",
    "    \n",
    "\n",
    "    \n",
    "    #lag variables 1 DAY\n",
    "    data['Close_Shift_1']=    data['Close'].shift(1)\n",
    "    data['Open_Shift_1']=    data['Open'].shift(1)\n",
    "    \n",
    "    #lag variables 1 WEEK\n",
    "    data['Close_Shift_5']=    data['Close'].shift(5)\n",
    "    data['Open_Shift_5']=    data['Open'].shift(5)\n",
    "    \n",
    "    \n",
    "    #prev_day_hi_or_low close\n",
    "    data['Prev_Day_Compare_Close'] = data['Close']-data['Close_Shift_1']\n",
    "    data['Prev_Day_Growth_Close'] = (data['Close']-data['Close_Shift_1'])/data['Close_Shift_1']\n",
    "    \n",
    "    \n",
    "    #prev_day_hi_or_low open\n",
    "    data['Prev_Day_Compare_Open'] = data['Open']-data['Open_Shift_1']\n",
    "    data['Prev_Day_Growth_Open'] = (data['Open']-data['Open_Shift_1'])/data['Open_Shift_1']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #prev_day_hi_or_low close\n",
    "    data['Prev_Week_Compare_Close'] = data['Close']-data['Close_Shift_5']\n",
    "    data['Prev_Week_Growth_Close'] = (data['Close']-data['Close_Shift_5'])/data['Close_Shift_5']\n",
    "    \n",
    "    \n",
    "    #prev_day_hi_or_low open\n",
    "    data['Prev_Week_Compare_Open'] = data['Open']-data['Open_Shift_5']\n",
    "    data['Prev_Week_Growth_Open'] = (data['Open']-data['Open_Shift_5'])/data['Open_Shift_5']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data=data.iloc[5:]\n",
    "    data\n",
    "\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "ticker='VXD'\n",
    "start = '2020-01-01'\n",
    "SDOW = generate_stock_data(start,now,ticker)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('{} Close'.format(ticker))\n",
    "\n",
    "plt.plot(SDOW['Date'],SDOW['Open'])\n",
    "\n",
    "plt.plot(SDOW['Date'],SDOW['5Day_Moving_Average_Open'])\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('{} Trade Volume'.format(ticker))\n",
    "\n",
    "\n",
    "plt.bar(SDOW['Date'],SDOW['Volume'])\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOW_DF = SDOW.groupby('DOW_Mapped')['Open'].mean().reset_index()\n",
    "plt.title(\"Average Open Price per Day of Week\")\n",
    "plt.bar(DOW_DF['DOW_Mapped'],DOW_DF['Open'])\n",
    "plt.plot(DOW_DF['DOW_Mapped'],DOW_DF['Open'],'r-')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SDOW[['Date','26Day_Moving_Average_Close','12Day_Moving_Average_Close','MACD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(SDOW['Date'],SDOW['12Day_Moving_Average_Close'],label='Short MA',color='k')\n",
    "plt.plot(SDOW['Date'],SDOW['26Day_Moving_Average_Close'],label='Long MA',color='r')\n",
    "\n",
    "\n",
    "for values in range(len(SDOW)):\n",
    "    if values!=0:\n",
    "        if SDOW['MACD'].iloc[values]<0:\n",
    "            if SDOW['MACD'].iloc[values-1]>0:\n",
    "                plt.scatter(SDOW['Date'].iloc[values-1],SDOW['12Day_Moving_Average_Close'].iloc[values-1],marker='*',\n",
    "                       color='red',s=150)\n",
    "                \n",
    "    if SDOW['MACD'].iloc[values]>0:\n",
    "        if SDOW['MACD'].iloc[values-1]<0:\n",
    "            plt.scatter(SDOW['Date'].iloc[values-1],SDOW['12Day_Moving_Average_Close'].iloc[values-1],marker='*',\n",
    "                       color='green',s=150)\n",
    "            \n",
    "            \n",
    "plt.title('MA Analysis {}'.format(ticker))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### red star siginal a downward trend & green stars signal an upward trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.title('MACD Analysis {}'.format(ticker))\n",
    "plt.plot(SDOW['Date'],SDOW['MACD'],label='MACD')\n",
    "plt.plot(SDOW['Date'],SDOW['signal'],label='Signal')\n",
    "plt.hlines(0,start,now,'r')\n",
    "plt.bar(SDOW['Date'],SDOW['hist'])\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_quote_data_by_minute(symbol='SDOW', data_range='3d', data_interval='1m'):\n",
    "    res = requests.get('https://query1.finance.yahoo.com/v8/finance/chart/{symbol}?range={data_range}&interval={data_interval}'.format(**locals()),verify=True)\n",
    "    data = res.json()\n",
    "    body = data['chart']['result'][0]    \n",
    "    dt = datetime.datetime\n",
    "    dt = pd.Series(map(lambda x: arrow.get(x).datetime.replace(tzinfo=None), body['timestamp']), name='Datetime')\n",
    "    df = pd.DataFrame(body['indicators']['quote'][0], index=dt)\n",
    "    dg = pd.DataFrame(body['timestamp'])    \n",
    "    df = df.loc[:, ('open', 'high', 'low', 'close', 'volume')]\n",
    "    df.dropna(inplace=True)     #removing NaN rows\n",
    "    df.columns = ['OPEN', 'HIGH','LOW','CLOSE','VOLUME']    #Renaming columns in pandas\n",
    "    df=df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_by_min = get_quote_data_by_minute(symbol=\"SDOW\",data_range='1d', data_interval='1m')\n",
    "min_by_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "plt.plot(min_by_min['Datetime'],min_by_min['CLOSE'])\n",
    "\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# To extract fundamental data\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, json, pprint\n",
    "import numpy as np\n",
    "p = re.compile(r'root\\.App\\.main = (.*);')\n",
    "tickers = ['PLUG','FCEL']\n",
    "results = {}\n",
    "\n",
    "with requests.Session() as s:\n",
    "\n",
    "    for ticker in tickers:\n",
    "        r = s.get('https://finance.yahoo.com/quote/{}/key-statistics?p={}'.format(ticker,ticker))\n",
    "        data = json.loads(p.findall(r.text)[0])\n",
    "        key_stats = data['context']['dispatcher']['stores']['QuoteSummaryStore']\n",
    "        results.setdefault(ticker,[])\n",
    "        results[ticker]\n",
    "        try:\n",
    "            res = {'EnterPrise Value' :key_stats['defaultKeyStatistics']['enterpriseValue']['fmt']}\n",
    "            results[ticker].append(res)\n",
    "        except:\n",
    "            results[ticker].append({'EnterPrise Value':np.nan})\n",
    "            \n",
    "        try:\n",
    "            res = {'Trailing P/E' : key_stats['summaryDetail']['trailingPE']['fmt']}\n",
    "            results[ticker].append(res)\n",
    "        except:\n",
    "            results[ticker].append({'Trailing P/E':np.nan})\n",
    "            \n",
    "        try:\n",
    "            res = {'Forward P/E' : key_stats['summaryDetail']['forwardPE']['fmt']}\n",
    "            results[ticker].append(res)\n",
    "        except:\n",
    "            results[ticker].append({'Forward P/E':np.nan})\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            res = {'PEG Ratio (5 yr expected)' : key_stats['defaultKeyStatistics']['pegRatio']['fmt']}\n",
    "            results[ticker].append(res)\n",
    "        except:\n",
    "            results[ticker].append({'PEG Ratio (5 yr expected)':np.nan})\n",
    "            \n",
    "        try:\n",
    "            res = {'Return on Assets' : key_stats['financialData']['returnOnAssets']['fmt']}\n",
    "            results[ticker].append(res)\n",
    "        except:\n",
    "            results[ticker].append({\"Return on Assets\":np.nan})\n",
    "            \n",
    "        try:\n",
    "            res = {'Quarterly Revenue Growth' : key_stats['financialData']['revenueGrowth']['fmt']}\n",
    "            results[ticker].append(res)\n",
    "        except:\n",
    "            results[ticker].append({\"Quarterly Revenue Growth\":np.nan})\n",
    "            \n",
    "        res = {'Company' : ticker}\n",
    "        results[ticker].append(res)    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests, re, json, pprint\n",
    "import numpy as np\n",
    "p = re.compile(r'root\\.App\\.main = (.*);')\n",
    "tickers = ['PLUG','FCEL']\n",
    "q_results = {}\n",
    "main_keys = ['trailingPsRatio', \n",
    "             'quarterlyPbRatio', \n",
    "             'quarterlyForwardPeRatio',\n",
    "             'quarterlyMarketCap', \n",
    "             'quarterlyPeRatio', \n",
    "             'trailingMarketCap',\n",
    "             'trailingEnterprisesValueEBITDARatio',\n",
    "             'quarterlyEnterprisesValueEBITDARatio', \n",
    "             'trailingForwardPeRatio', \n",
    "             'trailingEnterpriseValue',\n",
    "             'trailingPeRatio', \n",
    "             'quarterlyEnterprisesValueRevenueRatio', \n",
    "             'quarterlyPsRatio', \n",
    "             'trailingEnterprisesValueRevenueRatio', \n",
    "             'quarterlyPegRatio', \n",
    "             'trailingPbRatio',\n",
    "             'quarterlyEnterpriseValue', \n",
    "             'trailingPegRatio', \n",
    "             'timestamp']\n",
    "\n",
    "with requests.Session() as s:\n",
    "\n",
    "    for ticker in tickers:\n",
    "        r = s.get('https://finance.yahoo.com/quote/{}/key-statistics?p={}'.format(ticker,ticker))\n",
    "        data = json.loads(p.findall(r.text)[0])\n",
    "        \n",
    "        key_stats = data['context']['dispatcher']['stores']['QuoteTimeSeriesStore']\n",
    "        \n",
    "        q_results.setdefault(ticker,[])\n",
    "        for mk in main_keys:\n",
    "            try:\n",
    "                res = {mk: key_stats['timeSeries'][mk][1]['reportedValue']['raw']}\n",
    "                \n",
    "                q_results[ticker].append(res)\n",
    "            except:\n",
    "                q_results[ticker].append({mk:np.nan})\n",
    "            \n",
    "        res = {'Company' : ticker}\n",
    "        q_results[ticker].append(res)  \n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finstats = {}\n",
    "\n",
    "for k in results.keys():\n",
    "    c = results[k]\n",
    "    for ix in range(len(c)):\n",
    "        for key,val in  c[ix].items():\n",
    "            finstats.setdefault(key,[])\n",
    "            finstats[key].append(val)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstat = pd.DataFrame(finstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finstats_q = {}\n",
    "\n",
    "for k in q_results.keys():\n",
    "    c = q_results[k]\n",
    "    for ix in range(len(c)):\n",
    "        for key,val in  c[ix].items():\n",
    "            finstats_q.setdefault(key,[])\n",
    "            finstats_q[key].append(val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fstatsq = pd.DataFrame(finstats_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(fstat,fstatsq,on='Company')\n",
    "full_df_transpose=full_df.T\n",
    "full_df_transpose.columns = list(full_df['Company'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_df_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
